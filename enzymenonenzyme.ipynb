{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKEBJ7IdJsdQlqMSKZ9xea",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraCernyskovaite/enzyme-vs-nonenzyme/blob/main/enzymenonenzyme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG1Rtu8lZUBl",
        "outputId": "5d4fe396-5d7c-4784-fb28-fddd8e2eea93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Biopython nerastas. Biochemines savybes (išskyrus length) bus 0.0.\n",
            "======================================================================\n",
            "ISPLESTAS ENZYME KLASIFIKATORIUS\n",
            "Su NCBI Duomenimis + Patobulinimai\n",
            "======================================================================\n",
            "\n",
            "Naujos funkcijos:\n",
            "  1. Data Augmentation - 2x daugiau duomenų\n",
            "  2. Biocheminės savybės - 5 papildomi požymiai\n",
            "  3. Multi-Modal Model - sekos + savybės\n",
            "  4. Ensemble - CNN+BiLSTM + Random Forest\n",
            "  5. Feature Importance - kas svarbiausia?\n",
            "  6. Train/Val/Test padalinimas (70/15/15)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "DATA AUGMENTATION - Duomenu Isplėtimas\n",
            "======================================================================\n",
            "OK Augmentation funkcijos sukurtos.\n",
            "\n",
            "======================================================================\n",
            "BIOCHEMINIU SAVYBIU SKAICIAVIMAS (TIK 5 SAVYBES)\n",
            "======================================================================\n",
            "ĮSPĖJIMAS: Biopython nėra – bus tik length, kiti 0.0 (įdiek: pip install biopython)\n",
            "\n",
            "======================================================================\n",
            "NCBI DUOMENŲ UŽKROVIMAS\n",
            "======================================================================\n",
            "NCBI duomenys užkrauti: 3941 sekų\n",
            "  Klasių balansas: Counter({1: 2062, 0: 1879})\n",
            "  Sekų ilgiai: min=80, max=3802, mean=502\n",
            "\n",
            "======================================================================\n",
            "DATA AUGMENTATION - Kuriami papildomi duomenys\n",
            "======================================================================\n",
            "\n",
            "Po augmentation:\n",
            "  Originalus (NCBI): 3941\n",
            "  Augmented: 3941\n",
            "  VISO: 7882 sekų\n",
            "  Klasių balansas: Counter({1: 4124, 0: 3758})\n",
            "OK Išsaugota: augmented_dataset.csv\n",
            "\n",
            "======================================================================\n",
            "BIOCHEMINIŲ SAVYBIŲ SKAIČIAVIMAS (TIK 5)\n",
            "======================================================================\n",
            "INFO: Skaičiuojama... (gali užtrukti kelias minutes)\n",
            "  Apdorota: 500/7882\n",
            "  Apdorota: 1000/7882\n",
            "  Apdorota: 1500/7882\n",
            "  Apdorota: 2000/7882\n",
            "  Apdorota: 2500/7882\n",
            "  Apdorota: 3000/7882\n",
            "  Apdorota: 3500/7882\n",
            "  Apdorota: 4000/7882\n",
            "  Apdorota: 4500/7882\n",
            "  Apdorota: 5000/7882\n",
            "  Apdorota: 5500/7882\n",
            "  Apdorota: 6000/7882\n",
            "  Apdorota: 6500/7882\n",
            "  Apdorota: 7000/7882\n",
            "  Apdorota: 7500/7882\n",
            "\n",
            "Biocheminės savybės apskaičiuotos: 7882 sekų\n",
            "  Požymių skaičius: 5\n",
            "  Požymiai: ['length', 'molecular_weight', 'isoelectric_point', 'gravy', 'aromaticity']\n",
            "Savybės normalizuotos (mean=0, std=1)\n",
            "\n",
            "======================================================================\n",
            "DUOMENŲ PADALINIMAS\n",
            "======================================================================\n",
            "Padalinimas (70/15/15):\n",
            "  Train: 5517 (70.0%)\n",
            "  Val:   1182 (15.0%)\n",
            "  Test:  1183 (15.0%)\n",
            "\n",
            "  Sekų forma: (5517, 512)\n",
            "  Bio forma:  (5517, 5)\n",
            "\n",
            "Class weights: {0: 1.0488593155893535, 1: 0.9554901281607204}\n",
            "\n",
            "======================================================================\n",
            "MULTI-MODAL MODELIS\n",
            "======================================================================\n",
            "\n",
            "OK Multi-modal modelis sukurtas!\n",
            "  Parametrų: 304,673\n",
            "  2 įvestys: Sekos (512) + Bio savybės (5)\n",
            "\n",
            "======================================================================\n",
            "MODELIO TRENIRAVIMAS\n",
            "======================================================================\n",
            "Epoch 1/20\n",
            "87/87 - 120s - 1s/step - accuracy: 0.7087 - auc: 0.7803 - loss: 0.5546 - val_accuracy: 0.5474 - val_auc: 0.7589 - val_loss: 1.1222 - learning_rate: 1.0000e-03\n",
            "Epoch 2/20\n",
            "87/87 - 140s - 2s/step - accuracy: 0.8693 - auc: 0.9267 - loss: 0.3393 - val_accuracy: 0.5990 - val_auc: 0.8586 - val_loss: 1.0195 - learning_rate: 1.0000e-03\n",
            "Epoch 3/20\n",
            "87/87 - 109s - 1s/step - accuracy: 0.8954 - auc: 0.9558 - loss: 0.2651 - val_accuracy: 0.4763 - val_auc: 0.7133 - val_loss: 2.8455 - learning_rate: 1.0000e-03\n",
            "Epoch 4/20\n",
            "87/87 - 111s - 1s/step - accuracy: 0.9023 - auc: 0.9608 - loss: 0.2532 - val_accuracy: 0.6853 - val_auc: 0.9518 - val_loss: 0.8369 - learning_rate: 1.0000e-03\n",
            "Epoch 5/20\n",
            "87/87 - 140s - 2s/step - accuracy: 0.9282 - auc: 0.9792 - loss: 0.1820 - val_accuracy: 0.8968 - val_auc: 0.9750 - val_loss: 0.2519 - learning_rate: 1.0000e-03\n",
            "Epoch 6/20\n",
            "87/87 - 114s - 1s/step - accuracy: 0.9570 - auc: 0.9896 - loss: 0.1231 - val_accuracy: 0.9332 - val_auc: 0.9870 - val_loss: 0.1906 - learning_rate: 1.0000e-03\n",
            "Epoch 7/20\n",
            "87/87 - 115s - 1s/step - accuracy: 0.9685 - auc: 0.9937 - loss: 0.0910 - val_accuracy: 0.9484 - val_auc: 0.9883 - val_loss: 0.1690 - learning_rate: 1.0000e-03\n",
            "Epoch 8/20\n",
            "87/87 - 115s - 1s/step - accuracy: 0.9712 - auc: 0.9944 - loss: 0.0875 - val_accuracy: 0.9763 - val_auc: 0.9919 - val_loss: 0.0918 - learning_rate: 1.0000e-03\n",
            "Epoch 9/20\n",
            "87/87 - 142s - 2s/step - accuracy: 0.9788 - auc: 0.9962 - loss: 0.0637 - val_accuracy: 0.9611 - val_auc: 0.9863 - val_loss: 0.1439 - learning_rate: 1.0000e-03\n",
            "Epoch 10/20\n",
            "87/87 - 111s - 1s/step - accuracy: 0.9779 - auc: 0.9977 - loss: 0.0579 - val_accuracy: 0.9645 - val_auc: 0.9954 - val_loss: 0.0968 - learning_rate: 1.0000e-03\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "87/87 - 143s - 2s/step - accuracy: 0.9763 - auc: 0.9957 - loss: 0.0728 - val_accuracy: 0.9687 - val_auc: 0.9931 - val_loss: 0.0986 - learning_rate: 1.0000e-03\n",
            "Epoch 12/20\n",
            "87/87 - 111s - 1s/step - accuracy: 0.9947 - auc: 0.9991 - loss: 0.0196 - val_accuracy: 0.9873 - val_auc: 0.9968 - val_loss: 0.0463 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "87/87 - 112s - 1s/step - accuracy: 0.9987 - auc: 1.0000 - loss: 0.0062 - val_accuracy: 0.9865 - val_auc: 0.9971 - val_loss: 0.0445 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "87/87 - 145s - 2s/step - accuracy: 0.9991 - auc: 1.0000 - loss: 0.0031 - val_accuracy: 0.9898 - val_auc: 0.9964 - val_loss: 0.0474 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "87/87 - 137s - 2s/step - accuracy: 0.9996 - auc: 1.0000 - loss: 0.0013 - val_accuracy: 0.9898 - val_auc: 0.9964 - val_loss: 0.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "87/87 - 111s - 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 6.2772e-04 - val_accuracy: 0.9890 - val_auc: 0.9965 - val_loss: 0.0505 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "87/87 - 115s - 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 4.5192e-04 - val_accuracy: 0.9907 - val_auc: 0.9965 - val_loss: 0.0507 - learning_rate: 2.5000e-04\n",
            "Epoch 18/20\n",
            "87/87 - 142s - 2s/step - accuracy: 0.9991 - auc: 0.9996 - loss: 0.0044 - val_accuracy: 0.9873 - val_auc: 0.9971 - val_loss: 0.0540 - learning_rate: 2.5000e-04\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "87/87 - 111s - 1s/step - accuracy: 0.9991 - auc: 1.0000 - loss: 0.0031 - val_accuracy: 0.9738 - val_auc: 0.9921 - val_loss: 0.1262 - learning_rate: 2.5000e-04\n",
            "Epoch 20/20\n",
            "87/87 - 109s - 1s/step - accuracy: 0.9987 - auc: 0.9998 - loss: 0.0037 - val_accuracy: 0.9882 - val_auc: 0.9965 - val_loss: 0.0483 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\n",
            "Treniravimas baigtas!\n",
            "\n",
            "======================================================================\n",
            "TESTAVIMO REZULTATAI\n",
            "======================================================================\n",
            "\n",
            "Multi-Modal Rezultatai:\n",
            "  Slenkstis: 0.695\n",
            "  Accuracy: 0.9822 (98.22%)\n",
            "  ROC-AUC: 0.9983\n",
            "\n",
            "========================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Enzyme     0.9788    0.9840    0.9814       564\n",
            "      Enzyme     0.9854    0.9806    0.9830       619\n",
            "\n",
            "    accuracy                         0.9822      1183\n",
            "   macro avg     0.9821    0.9823    0.9822      1183\n",
            "weighted avg     0.9823    0.9822    0.9823      1183\n",
            "\n",
            "\n",
            "Klaidų matrica:\n",
            "[[555   9]\n",
            " [ 12 607]]\n",
            "\n",
            "======================================================================\n",
            "ENSEMBLE MODELIS\n",
            "======================================================================\n",
            "\n",
            "Ensemble Rezultatai:\n",
            "  Accuracy: 0.9822 (98.22%)\n",
            "  ROC-AUC: 0.9833\n",
            "\n",
            "======================================================================\n",
            "BIOCHEMINIŲ SAVYBIŲ SVARBA (TIK 5)\n",
            "======================================================================\n",
            "\n",
            "TOP biocheminės savybės:\n",
            "  length              : 1.0000\n",
            "  molecular_weight    : 0.0000\n",
            "  isoelectric_point   : 0.0000\n",
            "  gravy               : 0.0000\n",
            "  aromaticity         : 0.0000\n",
            "\n",
            "======================================================================\n",
            "VIZUALIZACIJŲ GENERAVIMAS\n",
            "======================================================================\n",
            "\n",
            "Visi grafikai sugeneruoti!\n",
            "\n",
            "======================================================================\n",
            "REZULTATŲ EKSPORTAVIMAS\n",
            "======================================================================\n",
            "Išsaugota: all_predictions.csv (1183 įrašų)\n",
            "Išsaugotos klaidos: 21 (MM), 21 (Ensemble)\n",
            "Išsaugota: feature_importance.csv\n",
            "Išsaugota: final_report.json\n",
            "\n",
            "======================================================================\n",
            "GALUTINĖ SANTRAUKA\n",
            "======================================================================\n",
            "\n",
            "Duomenys:\n",
            "   NCBI originalūs: 3941\n",
            "   Po augmentation: 7882 (x2.0)\n",
            "   Biocheminių savybių: 5 (['length', 'molecular_weight', 'isoelectric_point', 'gravy', 'aromaticity'])\n",
            "\n",
            "Multi-Modal Modelis:\n",
            "   Accuracy: 0.9822 (98.22%)\n",
            "   ROC-AUC:  0.9983\n",
            "   Klaidos:  21\n",
            "\n",
            "Ensemble Modelis:\n",
            "   Accuracy: 0.9822 (98.22%)\n",
            "   ROC-AUC:  0.9833\n",
            "   Klaidos:  21\n",
            "\n",
            "Patobulinimas:\n",
            "   Accuracy: +0.00%\n",
            "   ROC-AUC:  +-0.0150\n",
            "\n",
            "TOP biocheminės savybės:\n",
            "   1. length               (1.0000)\n",
            "   2. molecular_weight     (0.0000)\n",
            "   3. isoelectric_point    (0.0000)\n",
            "   4. gravy                (0.0000)\n",
            "   5. aromaticity          (0.0000)\n",
            "\n",
            "Išsaugoti failai:\n",
            "   results_enhanced/models/best_multimodal.keras\n",
            "   results_enhanced/images/ (6 grafikai)\n",
            "   results_enhanced/reports/ (CSV + JSON)\n",
            "\n",
            "======================================================================\n",
            "PROJEKTAS BAIGTAS!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  ISPLESTAS ENZYME KLASIFIKATORIUS SU NCBI DUOMENIMIS\n",
        "#  + Data Augmentation\n",
        "#  + Multi-Modal Features (BIOCHEMINES SAVYBES - tik 5)\n",
        "#  + Ensemble Methods\n",
        "#  + Feature Importance\n",
        "# ============================================================\n",
        "\n",
        "import os, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, callbacks, optimizers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, roc_auc_score, roc_curve,\n",
        "    confusion_matrix, precision_recall_curve,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# BIOPYTHON – BIOCHEMINIŲ SAVYBIŲ SKAIČIAVIMUI\n",
        "# ------------------------------------------------------------\n",
        "try:\n",
        "    from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "    BIOPYTHON_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"WARNING: Biopython nerastas. Biochemines savybes (išskyrus length) bus 0.0.\")\n",
        "    BIOPYTHON_AVAILABLE = False\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# ATSITIKTINIŲ SKAIČIŲ SĖKLOS (REPRODUKUOJAMUMUI)\n",
        "# ------------------------------------------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# PAGRINDINIAI MODELIO PARAMETRAI\n",
        "# ------------------------------------------------------------\n",
        "MAX_LEN = 512\n",
        "EMB_DIM = 64\n",
        "BATCH = 64\n",
        "EPOCHS = 20\n",
        "LR = 1e-3\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FAILŲ IR REZULTATŲ KELIAI\n",
        "# ------------------------------------------------------------\n",
        "SNAP_CSV = \"ncbi_enzyme_dataset.csv\"\n",
        "RESULTS_DIR = \"results_enhanced\"\n",
        "\n",
        "Path(RESULTS_DIR).mkdir(exist_ok=True)\n",
        "for subdir in ['images', 'models', 'reports', 'augmented_data']:\n",
        "    Path(f\"{RESULTS_DIR}/{subdir}\").mkdir(exist_ok=True)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ISPLESTAS ENZYME KLASIFIKATORIUS\")\n",
        "print(\"Su NCBI Duomenimis + Patobulinimai\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nNaujos funkcijos:\")\n",
        "print(\"  1. Data Augmentation - 2x daugiau duomenų\")\n",
        "print(\"  2. Biocheminės savybės - 5 papildomi požymiai\")\n",
        "print(\"  3. Multi-Modal Model - sekos + savybės\")\n",
        "print(\"  4. Ensemble - CNN+BiLSTM + Random Forest\")\n",
        "print(\"  5. Feature Importance - kas svarbiausia?\")\n",
        "print(\"  6. Train/Val/Test padalinimas (70/15/15)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================\n",
        "# 1) SEKŲ KODAVIMAS\n",
        "# ============================================================\n",
        "AA = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "AA2IDX = {a: i+1 for i, a in enumerate(AA)}\n",
        "AA2IDX[\"X\"] = len(AA2IDX) + 1\n",
        "VOCAB_SIZE = len(AA2IDX) + 1\n",
        "\n",
        "def clean_aa(seq: str) -> str:\n",
        "    s = re.sub(r'[^A-Za-z]', '', str(seq)).upper()\n",
        "    s = s.replace(\"U\",\"C\").replace(\"O\",\"K\").replace(\"B\",\"D\") \\\n",
        "         .replace(\"Z\",\"E\").replace(\"J\",\"I\")\n",
        "    return \"\".join(ch if ch in AA2IDX else \"X\" for ch in s)\n",
        "\n",
        "def encode_seq(seq: str, max_len: int = MAX_LEN) -> np.ndarray:\n",
        "    ids = [AA2IDX.get(ch, AA2IDX[\"X\"]) for ch in str(seq)[:max_len]]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    return np.array(ids, dtype=np.int32)\n",
        "\n",
        "# ============================================================\n",
        "# 2) DATA AUGMENTATION\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA AUGMENTATION - Duomenu Isplėtimas\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def mutate_sequence(seq: str, mutation_rate: float = 0.02) -> str:\n",
        "    if len(seq) < 5:\n",
        "        return seq\n",
        "    seq_list = list(seq)\n",
        "    n_mutations = max(1, int(len(seq) * mutation_rate))\n",
        "    positions = random.sample(range(len(seq)), min(n_mutations, len(seq)))\n",
        "    for pos in positions:\n",
        "        seq_list[pos] = random.choice(AA)\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def insert_residues(seq: str, max_insertions: int = 3) -> str:\n",
        "    if len(seq) > MAX_LEN - 10:\n",
        "        return seq\n",
        "    seq_list = list(seq)\n",
        "    n_insertions = random.randint(1, max_insertions)\n",
        "    for _ in range(n_insertions):\n",
        "        pos = random.randint(0, len(seq_list))\n",
        "        aa = random.choice(AA)\n",
        "        seq_list.insert(pos, aa)\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def delete_residues(seq: str, max_deletions: int = 3) -> str:\n",
        "    if len(seq) < 20:\n",
        "        return seq\n",
        "    seq_list = list(seq)\n",
        "    n_deletions = random.randint(1, min(max_deletions, len(seq_list) - 10))\n",
        "    for _ in range(n_deletions):\n",
        "        if len(seq_list) > 10:\n",
        "            pos = random.randint(0, len(seq_list) - 1)\n",
        "            del seq_list[pos]\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def shuffle_segment(seq: str, segment_length: int = 10) -> str:\n",
        "    if len(seq) < segment_length * 2:\n",
        "        return seq\n",
        "    seq_list = list(seq)\n",
        "    start = random.randint(0, len(seq) - segment_length)\n",
        "    segment = seq_list[start:start+segment_length]\n",
        "    random.shuffle(segment)\n",
        "    seq_list[start:start+segment_length] = segment\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def augment_sequence(seq: str, n_augmentations: int = 1) -> list:\n",
        "    augmented = []\n",
        "    for _ in range(n_augmentations):\n",
        "        aug_type = random.choice(['mutate', 'insert', 'delete', 'shuffle', 'combo'])\n",
        "        if aug_type == 'mutate':\n",
        "            new_seq = mutate_sequence(seq, mutation_rate=random.uniform(0.01, 0.05))\n",
        "        elif aug_type == 'insert':\n",
        "            new_seq = insert_residues(seq, max_insertions=random.randint(1, 4))\n",
        "        elif aug_type == 'delete':\n",
        "            new_seq = delete_residues(seq, max_deletions=random.randint(1, 4))\n",
        "        elif aug_type == 'shuffle':\n",
        "            new_seq = shuffle_segment(seq, segment_length=random.randint(5, 12))\n",
        "        else:\n",
        "            new_seq = mutate_sequence(seq, mutation_rate=0.02)\n",
        "            if random.random() > 0.5:\n",
        "                new_seq = shuffle_segment(new_seq, segment_length=8)\n",
        "        augmented.append(new_seq)\n",
        "    return augmented\n",
        "\n",
        "print(\"OK Augmentation funkcijos sukurtos.\")\n",
        "\n",
        "# ============================================================\n",
        "# 3) BIOCHEMINIU SAVYBIU SKAICIAVIMAS (TIK 5 SAVYBES)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BIOCHEMINIU SAVYBIU SKAICIAVIMAS (TIK 5 SAVYBES)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "SELECTED_BIO_FEATURES = [\n",
        "    \"length\",\n",
        "    \"molecular_weight\",\n",
        "    \"isoelectric_point\",\n",
        "    \"gravy\",\n",
        "    \"aromaticity\",\n",
        "]\n",
        "\n",
        "def calculate_biochemical_features(seq: str) -> dict:\n",
        "    \"\"\"\n",
        "    Gražina TIK 5 savybes:\n",
        "    length, molecular_weight, isoelectric_point, gravy, aromaticity\n",
        "    \"\"\"\n",
        "    # Be Biopython – paliekam tik length, kitus nuliais, kad sistema nesugriūtų\n",
        "    if not BIOPYTHON_AVAILABLE:\n",
        "        return {\n",
        "            \"length\": float(len(seq)),\n",
        "            \"molecular_weight\": 0.0,\n",
        "            \"isoelectric_point\": 0.0,\n",
        "            \"gravy\": 0.0,\n",
        "            \"aromaticity\": 0.0,\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        clean_seq = ''.join([aa for aa in seq if aa in AA])\n",
        "        if len(clean_seq) < 5:\n",
        "            return None\n",
        "\n",
        "        analyzer = ProteinAnalysis(clean_seq)\n",
        "\n",
        "        features = {\n",
        "            \"length\": float(len(clean_seq)),\n",
        "            \"molecular_weight\": float(analyzer.molecular_weight()),\n",
        "            \"isoelectric_point\": float(analyzer.isoelectric_point()),\n",
        "            \"gravy\": float(analyzer.gravy()),\n",
        "            \"aromaticity\": float(analyzer.aromaticity()),\n",
        "        }\n",
        "\n",
        "        # garantuojam, kad grąžinam tik pasirinktus ir ta pačia tvarka\n",
        "        return {k: float(features.get(k, 0.0)) for k in SELECTED_BIO_FEATURES}\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "if BIOPYTHON_AVAILABLE:\n",
        "    print(\"OK Naudojamos 5 biocheminės savybės (su Biopython):\")\n",
        "    print(\"  1) length\")\n",
        "    print(\"  2) molecular_weight\")\n",
        "    print(\"  3) isoelectric_point (pI)\")\n",
        "    print(\"  4) gravy (angl. GRAVY)\")\n",
        "    print(\"  5) aromaticity\")\n",
        "else:\n",
        "    print(\"ĮSPĖJIMAS: Biopython nėra – bus tik length, kiti 0.0 (įdiek: pip install biopython)\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) DUOMENU UZKROVIMAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NCBI DUOMENŲ UŽKROVIMAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "assert os.path.exists(SNAP_CSV), f\"ERROR: Nerastas {SNAP_CSV}. Įkelk CSV faila!\"\n",
        "df_original = pd.read_csv(SNAP_CSV)\n",
        "assert {\"sequence\",\"label\"}.issubset(df_original.columns), \"CSV turi 'sequence' ir 'label'\"\n",
        "\n",
        "print(f\"NCBI duomenys užkrauti: {len(df_original)} sekų\")\n",
        "print(f\"  Klasių balansas: {Counter(df_original['label'])}\")\n",
        "print(f\"  Sekų ilgiai: min={df_original['sequence'].str.len().min()}, \"\n",
        "      f\"max={df_original['sequence'].str.len().max()}, \"\n",
        "      f\"mean={df_original['sequence'].str.len().mean():.0f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5) DATA AUGMENTATION TAIKYMAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA AUGMENTATION - Kuriami papildomi duomenys\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "augmented_data = []\n",
        "for idx, row in df_original.iterrows():\n",
        "    augmented_data.append({\n",
        "        'sequence': row['sequence'],\n",
        "        'label': row['label'],\n",
        "        'augmented': False,\n",
        "        'original_idx': idx\n",
        "    })\n",
        "    aug_seqs = augment_sequence(row['sequence'], n_augmentations=1)\n",
        "    for aug_seq in aug_seqs:\n",
        "        augmented_data.append({\n",
        "            'sequence': aug_seq,\n",
        "            'label': row['label'],\n",
        "            'augmented': True,\n",
        "            'original_idx': idx\n",
        "        })\n",
        "\n",
        "df_augmented = pd.DataFrame(augmented_data)\n",
        "\n",
        "print(f\"\\nPo augmentation:\")\n",
        "print(f\"  Originalus (NCBI): {(~df_augmented['augmented']).sum()}\")\n",
        "print(f\"  Augmented: {df_augmented['augmented'].sum()}\")\n",
        "print(f\"  VISO: {len(df_augmented)} sekų\")\n",
        "print(f\"  Klasių balansas: {Counter(df_augmented['label'])}\")\n",
        "\n",
        "df_augmented.to_csv(f\"{RESULTS_DIR}/augmented_data/augmented_dataset.csv\", index=False)\n",
        "print(f\"OK Išsaugota: augmented_dataset.csv\")\n",
        "\n",
        "# ============================================================\n",
        "# 6) BIOCHEMINIU SAVYBIU SKAICIAVIMAS VISIEMS DUOMENIMS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BIOCHEMINIŲ SAVYBIŲ SKAIČIAVIMAS (TIK 5)\")\n",
        "print(\"=\"*70)\n",
        "print(\"INFO: Skaičiuojama... (gali užtrukti kelias minutes)\")\n",
        "\n",
        "bio_features_list = []\n",
        "valid_indices = []\n",
        "\n",
        "for idx, row in df_augmented.iterrows():\n",
        "    seq = clean_aa(row['sequence'])\n",
        "    features = calculate_biochemical_features(seq)\n",
        "    if features is not None:\n",
        "        bio_features_list.append(features)\n",
        "        valid_indices.append(idx)\n",
        "\n",
        "    if (idx + 1) % 500 == 0:\n",
        "        print(f\"  Apdorota: {idx + 1}/{len(df_augmented)}\")\n",
        "\n",
        "df_augmented = df_augmented.iloc[valid_indices].reset_index(drop=True)\n",
        "bio_features_df = pd.DataFrame(bio_features_list, columns=SELECTED_BIO_FEATURES)\n",
        "\n",
        "print(f\"\\nBiocheminės savybės apskaičiuotos: {len(bio_features_df)} sekų\")\n",
        "print(f\"  Požymių skaičius: {bio_features_df.shape[1]}\")\n",
        "print(f\"  Požymiai: {list(bio_features_df.columns)}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "bio_features_scaled = scaler.fit_transform(bio_features_df)\n",
        "print(\"Savybės normalizuotos (mean=0, std=1)\")\n",
        "\n",
        "# ============================================================\n",
        "# 7) DUOMENŲ PADALINIMAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DUOMENŲ PADALINIMAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "idx_all = np.arange(len(df_augmented))\n",
        "\n",
        "idx_train, idx_tmp = train_test_split(\n",
        "    idx_all, test_size=0.30,\n",
        "    stratify=df_augmented[\"label\"],\n",
        "    random_state=SEED\n",
        ")\n",
        "idx_val, idx_test = train_test_split(\n",
        "    idx_tmp, test_size=0.50,\n",
        "    stratify=df_augmented[\"label\"].iloc[idx_tmp],\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_seq_all = np.vstack([encode_seq(clean_aa(s)) for s in df_augmented[\"sequence\"]])\n",
        "X_bio_all = bio_features_scaled\n",
        "y_all = df_augmented[\"label\"].astype(int).to_numpy()\n",
        "\n",
        "X_seq_train, y_train = X_seq_all[idx_train], y_all[idx_train]\n",
        "X_seq_val, y_val     = X_seq_all[idx_val],   y_all[idx_val]\n",
        "X_seq_test, y_test   = X_seq_all[idx_test],  y_all[idx_test]\n",
        "\n",
        "X_bio_train = X_bio_all[idx_train]\n",
        "X_bio_val   = X_bio_all[idx_val]\n",
        "X_bio_test  = X_bio_all[idx_test]\n",
        "\n",
        "print(\"Padalinimas (70/15/15):\")\n",
        "print(f\"  Train: {len(y_train)} ({len(y_train)/len(df_augmented)*100:.1f}%)\")\n",
        "print(f\"  Val:   {len(y_val)} ({len(y_val)/len(df_augmented)*100:.1f}%)\")\n",
        "print(f\"  Test:  {len(y_test)} ({len(y_test)/len(df_augmented)*100:.1f}%)\")\n",
        "print(f\"\\n  Sekų forma: {X_seq_train.shape}\")\n",
        "print(f\"  Bio forma:  {X_bio_train.shape}\")\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "class_weights = {int(c): float(w) for c, w in zip(classes, cw)}\n",
        "print(f\"\\nClass weights: {class_weights}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8) MULTI-MODAL MODELIS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MULTI-MODAL MODELIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def build_multimodal_model(vocab_size=VOCAB_SIZE, max_len=MAX_LEN,\n",
        "                           emb_dim=EMB_DIM, n_bio_features=5, lr=LR):\n",
        "    seq_input = layers.Input(shape=(max_len,), dtype=\"int32\", name=\"sequence_input\")\n",
        "    x1 = layers.Embedding(input_dim=vocab_size, output_dim=emb_dim)(seq_input)\n",
        "    x1 = layers.Conv1D(128, kernel_size=9, padding=\"same\", activation=\"relu\")(x1)\n",
        "    x1 = layers.BatchNormalization()(x1)\n",
        "    x1 = layers.MaxPooling1D(pool_size=2)(x1)\n",
        "    x1 = layers.Bidirectional(layers.LSTM(96, return_sequences=False))(x1)\n",
        "    x1 = layers.Dropout(0.5)(x1)\n",
        "    x1 = layers.Dense(128, activation=\"relu\")(x1)\n",
        "    x1 = layers.Dropout(0.3)(x1)\n",
        "\n",
        "    bio_input = layers.Input(shape=(n_bio_features,), name=\"bio_input\")\n",
        "    x2 = layers.Dense(64, activation=\"relu\")(bio_input)\n",
        "    x2 = layers.Dropout(0.3)(x2)\n",
        "    x2 = layers.Dense(32, activation=\"relu\")(x2)\n",
        "    x2 = layers.Dropout(0.2)(x2)\n",
        "\n",
        "    merged = layers.concatenate([x1, x2])\n",
        "    x = layers.Dense(128, activation=\"relu\")(merged)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "\n",
        "    model = Model(inputs=[seq_input, bio_input], outputs=out, name=\"MultiModal_Enzyme\")\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model_mm = build_multimodal_model(n_bio_features=X_bio_train.shape[1])\n",
        "print(\"\\nOK Multi-modal modelis sukurtas!\")\n",
        "print(f\"  Parametrų: {model_mm.count_params():,}\")\n",
        "print(f\"  2 įvestys: Sekos ({MAX_LEN}) + Bio savybės ({X_bio_train.shape[1]})\")\n",
        "\n",
        "# ============================================================\n",
        "# 9) TRENIRAVIMAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODELIO TRENIRAVIMAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "cb = [\n",
        "    callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=5,\n",
        "                            restore_best_weights=True, verbose=1),\n",
        "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3,\n",
        "                               min_lr=1e-6, verbose=1),\n",
        "    callbacks.ModelCheckpoint(f\"{RESULTS_DIR}/models/best_multimodal.keras\",\n",
        "                              monitor=\"val_auc\", mode=\"max\",\n",
        "                              save_best_only=True, verbose=0)\n",
        "]\n",
        "\n",
        "history = model_mm.fit(\n",
        "    [X_seq_train, X_bio_train], y_train,\n",
        "    validation_data=([X_seq_val, X_bio_val], y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    class_weight=class_weights,\n",
        "    verbose=2,\n",
        "    callbacks=cb\n",
        ")\n",
        "print(\"\\nTreniravimas baigtas!\")\n",
        "\n",
        "# ============================================================\n",
        "# 10) ĮVERTINIMAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTAVIMO REZULTATAI\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "probs_mm = model_mm.predict([X_seq_test, X_bio_test], verbose=0).ravel()\n",
        "\n",
        "val_probs = model_mm.predict([X_seq_val, X_bio_val], verbose=0).ravel()\n",
        "p, r, th = precision_recall_curve(y_val, val_probs)\n",
        "f1 = 2 * p * r / (p + r + 1e-9)\n",
        "best_tau = float(th[np.argmax(f1[:-1])]) if len(th) > 0 else 0.5\n",
        "\n",
        "preds_mm = (probs_mm >= best_tau).astype(int)\n",
        "acc_mm = (preds_mm == y_test).mean()\n",
        "auc_mm = roc_auc_score(y_test, probs_mm)\n",
        "\n",
        "print(\"\\nMulti-Modal Rezultatai:\")\n",
        "print(f\"  Slenkstis: {best_tau:.3f}\")\n",
        "print(f\"  Accuracy: {acc_mm:.4f} ({acc_mm*100:.2f}%)\")\n",
        "print(f\"  ROC-AUC: {auc_mm:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(classification_report(\n",
        "    y_test, preds_mm,\n",
        "    digits=4,\n",
        "    target_names=['Non-Enzyme', 'Enzyme']\n",
        "))\n",
        "\n",
        "cm_mm = confusion_matrix(y_test, preds_mm)\n",
        "print(\"\\nKlaidų matrica:\")\n",
        "print(cm_mm)\n",
        "\n",
        "# ============================================================\n",
        "# 11) ENSEMBLE\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENSEMBLE MODELIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_preds_mm = model_mm.predict([X_seq_train, X_bio_train], verbose=0).ravel()\n",
        "test_preds_mm = probs_mm\n",
        "\n",
        "X_ensemble_train = np.column_stack([X_bio_train, train_preds_mm])\n",
        "X_ensemble_test = np.column_stack([X_bio_test, test_preds_mm])\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_ensemble_train, y_train)\n",
        "\n",
        "ensemble_probs = rf.predict_proba(X_ensemble_test)[:, 1]\n",
        "ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
        "\n",
        "acc_ens = (ensemble_preds == y_test).mean()\n",
        "auc_ens = roc_auc_score(y_test, ensemble_probs)\n",
        "\n",
        "print(\"\\nEnsemble Rezultatai:\")\n",
        "print(f\"  Accuracy: {acc_ens:.4f} ({acc_ens*100:.2f}%)\")\n",
        "print(f\"  ROC-AUC: {auc_ens:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 12) FEATURE IMPORTANCE (tik 5)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BIOCHEMINIŲ SAVYBIŲ SVARBA (TIK 5)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "rf_bio = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_bio.fit(X_bio_train, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': bio_features_df.columns,\n",
        "    'importance': rf_bio.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTOP biocheminės savybės:\")\n",
        "for _, row in feature_importance.iterrows():\n",
        "    print(f\"  {row['feature']:20s}: {row['importance']:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 13) VIZUALIZACIJOS (plt.show pašalinta)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VIZUALIZACIJŲ GENERAVIMAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# 1) Mokymo eiga\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Multi-Modal Modelio Mokymas', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0].plot(history.history['loss'], label='Train', linewidth=2)\n",
        "axes[0].plot(history.history['val_loss'], label='Val', linewidth=2)\n",
        "axes[0].set_title('Nuostolis (Loss)', fontweight='bold')\n",
        "axes[0].set_xlabel('Epocha'); axes[0].legend()\n",
        "\n",
        "axes[1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
        "axes[1].plot(history.history['val_accuracy'], label='Val', linewidth=2)\n",
        "axes[1].set_title('Tikslumas (Accuracy)', fontweight='bold')\n",
        "axes[1].set_xlabel('Epocha'); axes[1].legend()\n",
        "\n",
        "axes[2].plot(history.history['auc'], label='Train', linewidth=2)\n",
        "axes[2].plot(history.history['val_auc'], label='Val', linewidth=2)\n",
        "axes[2].set_title('AUC', fontweight='bold')\n",
        "axes[2].set_xlabel('Epocha'); axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/01_training.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 2) ROC kreivės\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "fpr_mm, tpr_mm, _ = roc_curve(y_test, probs_mm)\n",
        "fpr_ens, tpr_ens, _ = roc_curve(y_test, ensemble_probs)\n",
        "\n",
        "ax.plot(fpr_mm, tpr_mm, label='Multi-Modal', linewidth=2.5)\n",
        "ax.plot(fpr_ens, tpr_ens, label='Ensemble', linewidth=2.5)\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Atsitiktinis')\n",
        "\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Kreivių Palyginimas')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/02_roc.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 3) Feature importance (tik 5)\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "top_features = feature_importance.head(len(SELECTED_BIO_FEATURES))\n",
        "ax.barh(top_features['feature'], top_features['importance'])\n",
        "ax.set_xlabel('Svarba (Importance)')\n",
        "ax.set_title('Biocheminių Savybių Svarba (5 požymiai)')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/03_feature_importance.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 4) Confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "fig.suptitle('Klaidu Matricos', fontsize=16)\n",
        "\n",
        "ConfusionMatrixDisplay(cm_mm, display_labels=['Non-Enzyme', 'Enzyme']).plot(ax=axes[0])\n",
        "ConfusionMatrixDisplay(\n",
        "    confusion_matrix(y_test, ensemble_preds),\n",
        "    display_labels=['Non-Enzyme', 'Enzyme']\n",
        ").plot(ax=axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/04_confusion.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 5) Precision–Recall\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "prec_mm, rec_mm, _ = precision_recall_curve(y_test, probs_mm)\n",
        "prec_ens, rec_ens, _ = precision_recall_curve(y_test, ensemble_probs)\n",
        "\n",
        "ax.plot(rec_mm, prec_mm, label='Multi-Modal', linewidth=2.5)\n",
        "ax.plot(rec_ens, prec_ens, label='Ensemble', linewidth=2.5)\n",
        "\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_title('Precision–Recall Kreivės')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/05_pr_curves.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 6) Modelių palyginimas\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "models_ = ['Multi-Modal', 'Ensemble']\n",
        "accuracies = [acc_mm, acc_ens]\n",
        "aucs = [auc_mm, auc_ens]\n",
        "\n",
        "x = np.arange(len(models_))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(x - width/2, accuracies, width, label='Accuracy')\n",
        "ax.bar(x + width/2, aucs, width, label='ROC-AUC')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models_)\n",
        "ax.set_ylabel('Reikšmė')\n",
        "ax.set_title('Modelių Palyginimas')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/images/06_comparison.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisi grafikai sugeneruoti!\")\n",
        "\n",
        "# ============================================================\n",
        "# 14) EKSPORTAS\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REZULTATŲ EKSPORTAVIMAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_results = df_augmented.iloc[idx_test].reset_index(drop=True)\n",
        "df_results['multimodal_prob'] = probs_mm\n",
        "df_results['multimodal_pred'] = preds_mm\n",
        "df_results['ensemble_prob'] = ensemble_probs\n",
        "df_results['ensemble_pred'] = ensemble_preds\n",
        "df_results['correct_mm'] = (preds_mm == y_test)\n",
        "df_results['correct_ens'] = (ensemble_preds == y_test)\n",
        "df_results['true_label'] = y_test\n",
        "\n",
        "for col in bio_features_df.columns:\n",
        "    df_results[f'bio_{col}'] = bio_features_df.iloc[idx_test][col].values\n",
        "\n",
        "df_results.to_csv(f'{RESULTS_DIR}/reports/all_predictions.csv', index=False)\n",
        "print(f\"Išsaugota: all_predictions.csv ({len(df_results)} įrašų)\")\n",
        "\n",
        "errors_mm = df_results[~df_results['correct_mm']].copy()\n",
        "errors_ens = df_results[~df_results['correct_ens']].copy()\n",
        "errors_mm.to_csv(f'{RESULTS_DIR}/reports/errors_multimodal.csv', index=False)\n",
        "errors_ens.to_csv(f'{RESULTS_DIR}/reports/errors_ensemble.csv', index=False)\n",
        "print(f\"Išsaugotos klaidos: {len(errors_mm)} (MM), {len(errors_ens)} (Ensemble)\")\n",
        "\n",
        "feature_importance.to_csv(f'{RESULTS_DIR}/reports/feature_importance.csv', index=False)\n",
        "print(\"Išsaugota: feature_importance.csv\")\n",
        "\n",
        "report = {\n",
        "    'metadata': {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'original_data': SNAP_CSV,\n",
        "        'original_samples': int(len(df_original)),\n",
        "        'augmented_samples': int(len(df_augmented)),\n",
        "        'augmentation_ratio': float(len(df_augmented) / max(len(df_original), 1)),\n",
        "        'seed': SEED\n",
        "    },\n",
        "    'data': {\n",
        "        'train_size': int(len(y_train)),\n",
        "        'val_size': int(len(y_val)),\n",
        "        'test_size': int(len(y_test)),\n",
        "        'n_bio_features': int(X_bio_train.shape[1]),\n",
        "        'bio_features': list(bio_features_df.columns)\n",
        "    },\n",
        "    'multimodal_results': {\n",
        "        'threshold': float(best_tau),\n",
        "        'accuracy': float(acc_mm),\n",
        "        'roc_auc': float(auc_mm),\n",
        "        'errors': int((preds_mm != y_test).sum())\n",
        "    },\n",
        "    'ensemble_results': {\n",
        "        'accuracy': float(acc_ens),\n",
        "        'roc_auc': float(auc_ens),\n",
        "        'errors': int((ensemble_preds != y_test).sum())\n",
        "    },\n",
        "    'improvement': {\n",
        "        'accuracy_gain': float(acc_ens - acc_mm),\n",
        "        'auc_gain': float(auc_ens - auc_mm)\n",
        "    },\n",
        "    'top_features': feature_importance.to_dict('records')\n",
        "}\n",
        "\n",
        "with open(f'{RESULTS_DIR}/reports/final_report.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "print(\"Išsaugota: final_report.json\")\n",
        "\n",
        "# ============================================================\n",
        "# 15) GALUTINĖ SANTRAUKA\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GALUTINĖ SANTRAUKA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nDuomenys:\")\n",
        "print(f\"   NCBI originalūs: {len(df_original)}\")\n",
        "print(f\"   Po augmentation: {len(df_augmented)} (x{len(df_augmented)/len(df_original):.1f})\")\n",
        "print(f\"   Biocheminių savybių: {X_bio_train.shape[1]} ({list(bio_features_df.columns)})\")\n",
        "\n",
        "print(\"\\nMulti-Modal Modelis:\")\n",
        "print(f\"   Accuracy: {acc_mm:.4f} ({acc_mm*100:.2f}%)\")\n",
        "print(f\"   ROC-AUC:  {auc_mm:.4f}\")\n",
        "print(f\"   Klaidos:  {(preds_mm != y_test).sum()}\")\n",
        "\n",
        "print(\"\\nEnsemble Modelis:\")\n",
        "print(f\"   Accuracy: {acc_ens:.4f} ({acc_ens*100:.2f}%)\")\n",
        "print(f\"   ROC-AUC:  {auc_ens:.4f}\")\n",
        "print(f\"   Klaidos:  {(ensemble_preds != y_test).sum()}\")\n",
        "\n",
        "print(\"\\nPatobulinimas:\")\n",
        "print(f\"   Accuracy: +{(acc_ens - acc_mm)*100:.2f}%\")\n",
        "print(f\"   ROC-AUC:  +{(auc_ens - auc_mm):.4f}\")\n",
        "\n",
        "print(\"\\nTOP biocheminės savybės:\")\n",
        "for i, (_, row) in enumerate(feature_importance.iterrows(), start=1):\n",
        "    print(f\"   {i}. {row['feature']:20s} ({row['importance']:.4f})\")\n",
        "\n",
        "print(\"\\nIšsaugoti failai:\")\n",
        "print(f\"   {RESULTS_DIR}/models/best_multimodal.keras\")\n",
        "print(f\"   {RESULTS_DIR}/images/ (6 grafikai)\")\n",
        "print(f\"   {RESULTS_DIR}/reports/ (CSV + JSON)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROJEKTAS BAIGTAS!\")\n",
        "print(\"=\"*70)"
      ]
    }
  ]
}